{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a6306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run righteous-quail-432 at: http://localhost:5000/#/experiments/0/runs/4e51901f967e4ba98ccb6756d435f6c4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "Logged test_metric = 42 to local MLflow server\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Point MLflow at server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# Start a new run and a test metric\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"test_metric\", 42)\n",
    "\n",
    "print(\"Logged test_metric = 42 to local MLflow server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dadca859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already at project root: /home\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import get_ipython\n",
    "\n",
    "# move up one directory (only)\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == \"notebooks\":\n",
    "    get_ipython().run_line_magic(\"cd\", \"..\")\n",
    "    print(\"Moved up to project root:\", os.getcwd())\n",
    "else:\n",
    "    print(\"Already at project root:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6c5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 total videos\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Gather real & fake lists\n",
    "orig_paths = glob.glob(\"data/video_raw/original/*.mp4\")\n",
    "fake_paths = glob.glob(\"data/video_raw/manipulated/*.mp4\")\n",
    "\n",
    "# Combine into one list\n",
    "video_paths = orig_paths + fake_paths\n",
    "print(f\"Found {len(video_paths)} total videos\")\n",
    "\n",
    "# Create DataFrame with matching labels\n",
    "video_df = pd.DataFrame({\n",
    "    \"path\": video_paths,\n",
    "    \"label\": [\"real\"] * len(orig_paths) + [\"fake\"] * len(fake_paths)\n",
    "})\n",
    "\n",
    "# Peek\n",
    "video_df.head()\n",
    "print(video_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b698b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper to grab 1 frame per second\n",
    "def extract_frames(path, interval_sec=1, max_frames=5):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30 # default to 30 if unreadable\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while len(frames) < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Grab every 'interval_sec * fps' frames\n",
    "        if count % int(interval_sec * fps) == 0:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        count += 1\n",
    "    cap.release()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82c44875",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No videos found at data/video_raw/*.mp4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-> Frames extracted from first video:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(frames))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo videos found at data/video_raw/*.mp4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m fig, axs = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axs, frames):\n",
      "\u001b[31mRuntimeError\u001b[39m: No videos found at data/video_raw/*.mp4"
     ]
    }
   ],
   "source": [
    "# Shows 3 raw frames, 1 second apart\n",
    "if video_paths:\n",
    "    frames = extract_frames(video_paths[0], interval_sec=1, max_frames=3)\n",
    "    print(\"-> Frames extracted from first video:\", len(frames))\n",
    "else:\n",
    "    raise RuntimeError(\"No videos found at data/video_raw/*.mp4\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, img in zip(axs, frames):\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(os.path.basename(video_paths[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d49f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no frames for data/video_raw/original/21__kitchen_pan.mp4\n",
      "Warning: no frames for data/video_raw/original/15__walk_down_hall_angry.mp4\n",
      "Warning: no frames for data/video_raw/original/24__talking_against_wall.mp4\n",
      "Warning: no frames for data/video_raw/original/17__exit_phone_room.mp4\n",
      "Warning: no frames for data/video_raw/original/10__kitchen_still.mp4\n",
      "Warning: no frames for data/video_raw/original/26__outside_talking_still_laughing.mp4\n",
      "Warning: no frames for data/video_raw/original/12__talking_angry_couch.mp4\n",
      "Warning: no frames for data/video_raw/original/28__podium_speech_happy.mp4\n",
      "Warning: no frames for data/video_raw/original/20__walking_and_outside_surprised.mp4\n",
      "Warning: no frames for data/video_raw/original/13__walking_down_indoor_hall_disgust.mp4\n",
      "Warning: no frames for data/video_raw/original/02__meeting_serious.mp4\n",
      "Warning: no frames for data/video_raw/original/09__kitchen_pan.mp4\n",
      "Warning: no frames for data/video_raw/original/16__walking_and_outside_surprised.mp4\n",
      "Warning: no frames for data/video_raw/original/01__walking_down_indoor_hall_disgust.mp4\n",
      "Warning: no frames for data/video_raw/original/08__walking_down_street_outside_angry.mp4\n",
      "Warning: no frames for data/video_raw/original/07__walking_outside_cafe_disgusted.mp4\n",
      "Warning: no frames for data/video_raw/original/05__hugging_happy.mp4\n",
      "Warning: no frames for data/video_raw/original/26__walk_down_hall_angry.mp4\n",
      "Warning: no frames for data/video_raw/original/01__walk_down_hall_angry.mp4\n",
      "Warning: no frames for data/video_raw/original/04__outside_talking_still_laughing.mp4\n",
      "No shapes to plot\n"
     ]
    }
   ],
   "source": [
    "# Gather statistics on dataset\n",
    "shapes = []\n",
    "histograms =[]\n",
    "\n",
    "for vf in video_paths[:20]: # limit to first 20\n",
    "    f = extract_frames(vf, interval_sec=2, max_frames=1)\n",
    "    if not f: \n",
    "        print(\"Warning: no frames for\", vf)\n",
    "        continue\n",
    "    shapes.append(f[0].shape[:2])\n",
    "\n",
    "    print(\"-> Collected shapes:\", shapes[:5], \"... total\", len(shapes))\n",
    "\n",
    "    # Flattened intensity histogram\n",
    "    hist, _ = np.histogram(img.ravel(), bins=50, range=(0, 255))\n",
    "    histograms.append(hist)\n",
    "\n",
    "# Only plot if there is data\n",
    "if shapes:\n",
    "    # Plot distribution of heights and widths\n",
    "    heights, widths = zip(*shapes)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(heights, bins=10, alpha=0.7, label=\"height\")\n",
    "    plt.hist(widths, bins=10, alpha=0.7, label=\"width\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Frame dimension distribution (first 20 videos)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Pixels\")\n",
    "    plt.show\n",
    "else:\n",
    "    print(\"No shapes to plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-sentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
